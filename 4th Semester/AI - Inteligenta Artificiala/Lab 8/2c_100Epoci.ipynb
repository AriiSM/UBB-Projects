{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4e4f87-4019-44f1-87f2-14aaee37bad3",
   "metadata": {},
   "source": [
    "<h4> Pentru a adresa limitările de creativitate în poezia generată înlocuiți aleator cuvinte cu sinonime. Se cere ca sinonimele să fie obținute folosind embedding-uri. (i.e. Cuvântul ales e transformat în forma sa embedded și se alege embedding-ul cel mai apropiat care este convertit la string) </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9cfd5-0859-4c9e-a9fa-3726742bcb7a",
   "metadata": {},
   "source": [
    "<h1>Importuri</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ced655-af16-4a61-b47e-f765590459fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb0b3e-2022-41a1-8c59-27e5735deb8c",
   "metadata": {},
   "source": [
    "<h1>Citirea datelor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0cf402-2ce7-42a9-a97c-3e0fc18e0085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\")\n",
    "train_data = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97049cd8-7ce0-4172-baa7-792d31163c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numărul de linii = 3085117\n",
      "{'line': ['The Song of Hiawatha is based on the legends and stories of', 'many North American Indian tribes, but especially those of the', 'Ojibway Indians of northern Michigan, Wisconsin, and Minnesota.', 'They were collected by Henry Rowe Schoolcraft, the reknowned'], 'gutenberg_id': [19, 19, 19, 19]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Numărul de linii =\", len(train_data))\n",
    "print(train_data[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce072c0c-d277-4e94-b6ae-4e1aee7909fb",
   "metadata": {},
   "source": [
    "<h1>Cleaning DataSet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ca7c09-305f-4d92-b13b-e85597a17b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line': Value(dtype='string', id=None),\n",
       " 'gutenberg_id': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7312ca15-b0e0-4c80-aa5f-25f294c6a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numărul de propoziții = 21740946\n",
      "Primele 5 propoziții:\n",
      "['the', 'song', 'of', 'hiawatha', 'is']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = []\n",
    "    for example in text:\n",
    "        poem_text = example[\"line\"]  # Accesează textul poeziei din exemplu\n",
    "        poem_text = poem_text.lower()\n",
    "        poem_text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", poem_text)\n",
    "        tokens = word_tokenize(poem_text)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_text.extend(words)\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_poetry = clean_text(train_data)\n",
    "print(\"Numărul de propoziții =\", len(cleaned_poetry))\n",
    "print(\"Primele 5 propoziții:\")\n",
    "print(cleaned_poetry[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c6726-9d8c-43d4-9b5c-bdeb8e882cb9",
   "metadata": {},
   "source": [
    "<h1>Word2Vec</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3804279d-3d3d-4cba-9b28-62ddc16306c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=[cleaned_poetry], vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")\n",
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9c071-8508-4b0e-b990-297d1f6cacff",
   "metadata": {},
   "source": [
    "<h1>Antrenam modelul</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64496225-a9d3-4fc4-97eb-cc3860f2d619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8311201551, 9182398800)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(cleaned_poetry, total_examples=len(cleaned_poetry), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d4322-62ed-44b4-a91b-97d4f0530795",
   "metadata": {},
   "source": [
    "<h2>Random testing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52aa2fa6-1ae5-44be-8ff1-47e570c1bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dichten', 0.45711588859558105), ('smirching', 0.4185357987880707), ('unlovable', 0.41729921102523804), ('matricks', 0.4032917022705078), ('dämmernde', 0.4003211557865143), ('primordial', 0.39884865283966064), ('whiaesaes', 0.3972812592983246), ('ualere', 0.3962159752845764), ('anteferantur', 0.39552658796310425), ('neceslitie', 0.3954140543937683)]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['grandpa']  # get numpy vector of a word\n",
    "sims = model.wv.most_similar('grandpa', topn=10)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204e0f6-10a3-4e79-9ff4-4bf5b01b93d6",
   "metadata": {},
   "source": [
    "<h1>Crearea modelului Markov</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c102dfc3-a534-406a-a715-23bb0bed55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markov_model(cleaned_stories, n_gram):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \" if i + j + n_gram < len(cleaned_stories) else \"\"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a8e194-8499-42f2-bab3-f77564c4f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "markov_model = make_markov_model(cleaned_poetry, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b835e76-04af-4841-8983-2f30cd64e4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  242615\n"
     ]
    }
   ],
   "source": [
    "print(\"number of states = \", len(markov_model.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be594e-635e-43f6-9804-a2f85ba483eb",
   "metadata": {},
   "source": [
    "<h1>Generare text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d3ece22-1e53-498b-9acc-0f3f2825d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_model, limit, start):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aec5f2-9694-44d8-b967-4c4f52ca2e0c",
   "metadata": {},
   "source": [
    "<h1>Utilizare</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38ebdb66-e90d-493c-bd95-b504f8ad4a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with mind she \u001b[31mholdere (strayed)\u001b[0m \u001b[31mthe (from)\u001b[0m \u001b[31mof (their)\u001b[0m heels \u001b[31mthe (and)\u001b[0m \u001b[31mhis (made)\u001b[0m hem with natures \u001b[31mit (only)\u001b[0m have proved \u001b[31mstrike (nought)\u001b[0m me \u001b[31mjubileedom (yours)\u001b[0m my \n",
      "precontract and \u001b[31mthe (she)\u001b[0m \u001b[31myour (looked)\u001b[0m \u001b[31mthe (in)\u001b[0m \u001b[31mthe (his)\u001b[0m \u001b[31mdevoveat (name)\u001b[0m but nature to none learn \u001b[31mhis (the)\u001b[0m ledges the \u001b[31msongin (fruit)\u001b[0m and \u001b[31msalons (tempest)\u001b[0m \u001b[31mwater (found)\u001b[0m \n",
      "the frame while the dead or some melodious lay o \u001b[31mboldaeurotm (philomela)\u001b[0m \u001b[31mchauffeurs (talkd)\u001b[0m with numbers long swords and \u001b[31mjessie (mild)\u001b[0m his \n",
      "shoulder \u001b[31mroofes (pressing)\u001b[0m forward through the cleft shield he amid the kind \u001b[31mhiawatha (heart)\u001b[0m \u001b[31minicere (doth)\u001b[0m linger sweet so \u001b[31mpensacola (blissfully)\u001b[0m in flowing \n",
      "crystal carefully kept her speed \u001b[31mthen (fire)\u001b[0m and \u001b[31mcene (agin)\u001b[0m the mountains head the weight \u001b[31mhanc (oppressd)\u001b[0m of these he said when \n",
      "both man \u001b[31mthe (and)\u001b[0m though malice so slowly through \u001b[31mthe (and)\u001b[0m the victor ab omni \u001b[31moutspreading (priuata)\u001b[0m \u001b[31mvidentem (dolore)\u001b[0m \u001b[31mcruets (sevocat)\u001b[0m a calf bit \n",
      "not \u001b[31mhiawatha (to)\u001b[0m the world \u001b[31mthe (and)\u001b[0m love o chief as firstly for \u001b[31mcomedones (satan)\u001b[0m chief menestheus aeneas hopes \u001b[31mof (with)\u001b[0m \u001b[31msplits (faint)\u001b[0m with \n",
      "\u001b[31mhis (the)\u001b[0m \u001b[31mrushing (right)\u001b[0m and \u001b[31mthe (in)\u001b[0m han or ere night i have walkt forth \u001b[31mfrom (so)\u001b[0m \u001b[31mgutturis (well)\u001b[0m it is a \u001b[31mparon (warrior)\u001b[0m wide \n",
      "wings he meant or her inmost bosom \u001b[31mhiawatha (to)\u001b[0m the mounting \u001b[31mupon (sun)\u001b[0m lie \u001b[31mdrawhte (awake)\u001b[0m inflamed with loathing \u001b[31mventosa (sane)\u001b[0m with its \n",
      "\u001b[31mἔγνων (flames)\u001b[0m \u001b[31mthe (were)\u001b[0m \u001b[31mpropagandist (glad)\u001b[0m \u001b[31mare (here)\u001b[0m no not good and \u001b[31msollen (taught)\u001b[0m me a calmer grew here and florets round to nestor "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from termcolor import colored  \n",
    "\n",
    "replace_prob = 0.3  # Probabilitatea \n",
    "\n",
    "def replace_with_synonyms(word):\n",
    "    try:\n",
    "        synonyms = model.wv.most_similar(word, topn=10)  \n",
    "        synonym = synonyms[0][0]\n",
    "        return synonym, word \n",
    "    except:\n",
    "        return word, word  # Dacă nu găsim sinonim, returnăm cuvântul original\n",
    "\n",
    "poetry = generate_story(markov_model, 189, \"with\")\n",
    "words = poetry.split()  \n",
    "words_printed = 0 \n",
    "for word in words:\n",
    "    if words_printed % 19 == 0 and words_printed > 0:\n",
    "        print()  \n",
    "    if replace_prob == 1 or (replace_prob > 0 and random.random() < replace_prob):\n",
    "        synonym, original_word = replace_with_synonyms(word)\n",
    "        if original_word and original_word != synonym:  # Verificăm dacă cuvântul original și sinonimul sunt diferite\n",
    "            print(colored(f\"{synonym} ({original_word})\", 'red'), end=\" \")  \n",
    "        else:\n",
    "            print(synonym, end=\" \")  # Dacă nu sunt diferite, printăm doar sinonimul\n",
    "    else:\n",
    "        print(word, end=\" \")\n",
    "    words_printed += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
